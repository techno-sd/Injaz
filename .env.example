# ============================================
# iEditor Environment Configuration
# ============================================
# Copy this file to .env.local and fill in your values
# Never commit .env.local to version control

# ============================================
# DATABASE - Supabase
# ============================================
# Get these from: https://supabase.com/dashboard/project/_/settings/api
NEXT_PUBLIC_SUPABASE_URL=https://your-project.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=your-supabase-anon-key
SUPABASE_SERVICE_ROLE_KEY=your-service-role-key

# ============================================
# AI CONFIGURATION - OpenRouter (Recommended)
# ============================================
# Get your API key from: https://openrouter.ai/keys
# OpenRouter provides access to 200+ models from one API
OPENROUTER_API_KEY=your-openrouter-api-key

# Optional: Direct OpenAI fallback (used if OPENROUTER_API_KEY not set)
# OPENAI_API_KEY=your-openai-api-key
# OPENAI_BASE_URL=https://api.openai.com/v1

# ------------------------------------------------
# Model Configuration (OpenRouter model IDs)
# ------------------------------------------------
# RECOMMENDED - DeepSeek V3 (Best value, excellent quality):
#   - deepseek/deepseek-chat-v3-0324 - LATEST DeepSeek V3 (~$0.14/1M)
#   - deepseek/deepseek-chat - DeepSeek V3 stable
#   - deepseek/deepseek-coder - Best for code generation
#
# ALTERNATIVE Models:
#   - qwen/qwen-2.5-coder-32b-instruct - Strong coding
#   - anthropic/claude-3.5-haiku - Fast, good quality
#
# FREE Models:
#   - google/gemma-2-9b-it:free
#   - meta-llama/llama-3.2-3b-instruct:free
#
# PREMIUM Models (Best quality, higher cost):
#   - deepseek/deepseek-r1 - DeepSeek reasoning model
#   - anthropic/claude-sonnet-4 ($3/$15 per 1M)
#   - openai/gpt-4o ($2.5/$10 per 1M)

# Service-specific models (customize per task)
# CONTROLLER_MODEL: Planning & architecture (use premium reasoning model)
# CODEGEN_MODEL: Code generation (use fast, capable model)
# REVIEWER_MODEL: Code review (use capable model for quality checks)
CONTROLLER_MODEL=google/gemini-3-pro-preview
CODEGEN_MODEL=deepseek/deepseek-v3.2
REVIEWER_MODEL=deepseek/deepseek-v3.2
COMPLETION_AI_MODEL=deepseek/deepseek-v3.2
DEFAULT_AI_MODEL=deepseek/deepseek-v3.2
FALLBACK_MODEL=openai/gpt-4o-mini

# Optional: Custom models list for UI (JSON array)
# CUSTOM_MODELS=[{"id":"your/model","name":"Display Name","description":"Description","category":"recommended"}]

# ============================================
# INTEGRATIONS - GitHub
# ============================================
# Create OAuth App: https://github.com/settings/developers
# Callback URL: {APP_URL}/api/github/auth/callback
NEXT_PUBLIC_GITHUB_CLIENT_ID=your-github-client-id
GITHUB_CLIENT_SECRET=your-github-client-secret

# ============================================
# INTEGRATIONS - Vercel
# ============================================
# Create Integration: https://vercel.com/dashboard/integrations/console
# Callback URL: {APP_URL}/api/vercel/auth/callback
NEXT_PUBLIC_VERCEL_CLIENT_ID=your-vercel-oauth-client-id
VERCEL_CLIENT_ID=your-vercel-oauth-client-id
VERCEL_CLIENT_SECRET=your-vercel-oauth-client-secret

# ============================================
# APPLICATION
# ============================================
NEXT_PUBLIC_APP_URL=http://localhost:3000

# ============================================
# OPTIONAL - Feature Flags
# ============================================
# ENABLE_MOBILE_PREVIEW=true
# ENABLE_EXPO_QR=true
# DEBUG_AI=false
